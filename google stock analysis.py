# -*- coding: utf-8 -*-
"""AnjaliPriyadarshi_04411503123_IT_finalmlassignment

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13_UfCAQk_NIBT0OLhIJBClGIXptCZQLW
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression
from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
import seaborn as sns
from sklearn.cluster import KMeans

df = pd.read_csv("/content/googl_daily_prices.csv")
df = df.sort_values('date')
df['next_day_close'] = df['4. close'].shift(-1)
df.dropna(inplace=True)
df['target'] = np.where(df['next_day_close'] > df['4. close'], 'up', 'down')
X = df[['1. open', '2. high', '3. low', '4. close', '5. volume']]
y_reg = df['next_day_close']
y_clf = df['target']
le = LabelEncoder()
y_clf_encoded = le.fit_transform(y_clf)
X_train, X_test = train_test_split(X, test_size=0.2, random_state=0)
y_train_reg = y_reg.loc[X_train.index]
y_test_reg = y_reg.loc[X_test.index]
y_train_clf = y_clf.loc[X_train.index]
y_test_clf = y_clf.loc[X_test.index]
y_test_clf_encoded = le.transform(y_test_clf)

#linear regression
lr = LinearRegression()
lr.fit(X_train, y_train_reg)
y_pred_lr = lr.predict(X_test)
plt.figure(figsize=(12, 6))
plt.plot(y_test_reg.values, label='Actual', linewidth=2)
plt.plot(y_pred_lr, label='Linear Regression', linestyle='--')
plt.title('Actual vs Predicted Closing Prices (Linear Regression)')
plt.xlabel('Sample Index')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()
print("Linear Regression Metrics:")
print(f"RÂ² Score: {r2_score(y_test_reg, y_pred_lr):.4f}")
print(f"Mean Squared Error: {mean_squared_error(y_test_reg, y_pred_lr):.4f}")
print(f"Mean Absolute Error: {mean_absolute_error(y_test_reg, y_pred_lr):.4f}")

#lasso regression
lasso = Lasso(alpha=0.5)
lasso.fit(X_train, y_train_reg)
y_pred_lasso = lasso.predict(X_test)
plt.figure(figsize=(12, 6))
plt.plot(y_test_reg.values, label='Actual', linewidth=2)
plt.plot(y_pred_lasso, label='Lasso Regression', linestyle='--')
plt.title('Actual vs Predicted Closing Prices (Lasso Regression)')
plt.xlabel('Sample Index')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()
print("\nLasso Regression Metrics:")

print(f"RÂ² Score: {r2_score(y_test_reg, y_pred_lasso):.4f}")
print(f"Mean Squared Error: {mean_squared_error(y_test_reg, y_pred_lasso):.4f}")
print(f"Mean Absolute Error: {mean_absolute_error(y_test_reg, y_pred_lasso):.4f}")

#logistic regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train_clf)
y_pred_log = logreg.predict(X_test)
y_pred_log_encoded = le.transform(y_pred_log)
plt.figure(figsize=(10, 4))
plt.plot(y_test_clf_encoded, label='Actual (0=down, 1=up)', marker='o')
plt.plot(y_pred_log_encoded, label='Predicted', marker='x')
plt.title("Logistic Regression Classification (Actual vs Predicted)")
plt.xlabel("Sample Index")
plt.ylabel("Class")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
log_acc = accuracy_score(y_test_clf, y_pred_log)
log_cm = confusion_matrix(y_test_clf, y_pred_log)
log_report = classification_report(y_test_clf, y_pred_log)
print("\nLogistic Regression")
print(f"Accuracy: {log_acc:.4f}")
print("Confusion Matrix:")
print(log_cm)
print("Classification Report:")
print(log_report)

from sklearn.metrics import roc_curve, roc_auc_score

y_prob_log = logreg.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test_clf_encoded, y_prob_log)
roc_auc = roc_auc_score(y_test_clf_encoded, y_prob_log)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Logistic Regression')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

#knn classification
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train_clf)
y_pred_knn = knn.predict(X_test)
knn_acc = accuracy_score(y_test_clf, y_pred_knn)
knn_cm = confusion_matrix(y_test_clf, y_pred_knn)
knn_report = classification_report(y_test_clf, y_pred_knn)
print("\nKNN")
print(f"Accuracy: {knn_acc:.4f}")
print("Confusion Matrix:")
print(knn_cm)
print("Classification Report:")
print(knn_report)

y_prob_knn = knn.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_clf_encoded, y_prob_knn[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - KNN')
plt.legend(loc="lower right")
plt.grid()
plt.show()

#gaussian naive bayes classifier
gnb = GaussianNB()
gnb.fit(X_train, y_train_clf)
y_pred_gnb = gnb.predict(X_test)
gnb_acc = accuracy_score(y_test_clf, y_pred_gnb)
gnb_cm = confusion_matrix(y_test_clf, y_pred_gnb)
gnb_report = classification_report(y_test_clf, y_pred_gnb)
print("\nGaussian Naive Bayes")
print(f"Accuracy: {gnb_acc:.4f}")
print("Confusion Matrix:")
print(gnb_cm)
print("Classification Report:")
print(gnb_report)

y_prob_gnb = gnb.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_clf_encoded, y_prob_gnb[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - GNB')
plt.legend(loc="lower right")
plt.grid()
plt.show()

#bernoulli naive bayes classifier
bnb = BernoulliNB()
bnb.fit(X_train, y_train_clf)
y_pred_bnb = bnb.predict(X_test)
bnb_acc = accuracy_score(y_test_clf, y_pred_bnb)
bnb_cm = confusion_matrix(y_test_clf, y_pred_bnb)
bnb_report = classification_report(y_test_clf, y_pred_bnb)
print("\nBernoulli Naive Bayes")
print(f"Accuracy: {bnb_acc:.4f}")
print("Confusion Matrix:")
print(bnb_cm)
print("Classification Report:")
print(bnb_report)

y_prob_bnb = bnb.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_clf_encoded, y_prob_bnb[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - BNB')
plt.legend(loc="lower right")
plt.grid()
plt.show()

#decision tree classification
dt = DecisionTreeClassifier(criterion='entropy', random_state=0)
dt.fit(X_train, y_train_clf)
y_pred_dt = dt.predict(X_test)
dt_acc = accuracy_score(y_test_clf, y_pred_dt)
dt_cm = confusion_matrix(y_test_clf, y_pred_dt)
dt_report = classification_report(y_test_clf, y_pred_dt)
print("\nDecision Tree")
print(f"Accuracy: {dt_acc:.4f}")
print("Confusion Matrix:")
print(dt_cm)
print("Classification Report:")
print(dt_report)
from sklearn import tree
plt.figure(figsize=(30, 30))
tree.plot_tree(dt)
plt.show()

y_prob_dt = dt.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_clf_encoded, y_prob_dt[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - DT')
plt.legend(loc="lower right")
plt.grid()
plt.show()

#random forest classifier
rf = RandomForestClassifier(n_estimators=100,criterion='entropy', random_state=0)
rf.fit(X_train, y_train_clf)
y_pred_rf = rf.predict(X_test)
rf_acc = accuracy_score(y_test_clf, y_pred_rf)
rf_cm = confusion_matrix(y_test_clf, y_pred_rf)
rf_report = classification_report(y_test_clf, y_pred_rf)
print("\nRandom Forest")
print(f"Accuracy: {rf_acc:.4f}")
print("Confusion Matrix:")
print(rf_cm)
print("Classification Report:")
print(rf_report)

y_prob_rf = rf.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test_clf_encoded, y_prob_rf[:, 1])
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - RF')
plt.legend(loc="lower right")
plt.grid()
plt.show()

#SVM
classifier = SVC(kernel='rbf', random_state=0)
classifier.fit(X_train, y_train_clf)
y_pred= classifier.predict(X_test)
cm= confusion_matrix(y_test_clf, y_pred)
report = classification_report(y_test_clf, y_pred)
print("\nSVM")
print('Classification Report:')
print(report)
print('Confusion Matrix:')
print(cm)
print("Accuracy score:",accuracy_score(y_test_clf, y_pred))

#K MEANS CLUSTERING
plt.figure(figsize=(15,8))
#X=X.head(1000)
sns.scatterplot(x=X['1. open'], y=X['5. volume'])
plt.xlabel('1. open')
plt.ylabel('5. volume')
plt.title('Scatter plot of Open Price vs closing price')
plt.show()
wcss=[]
for i in range(1,40):
  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=2)
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)
plt.figure(figsize=(15,8))
plt.plot(range(1,40), wcss)
plt.title('The Elbow Point Graph')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('wcss')
plt.show()
kmeans = KMeans(n_clusters=2, init='k-means++', random_state=0)
Y = kmeans.fit_predict(X)
kmeans.cluster_centers_
plt.figure(figsize=(10,7))
plt.scatter(X.iloc[Y==0, 0], X.iloc[Y==0, 1], s=50, c='red', label='Cluster 1')
plt.scatter(X.iloc[Y==1, 0], X.iloc[Y==1, 1], s=50, c='blue', label='Cluster 2')
plt.scatter(X.iloc[Y==2, 0], X.iloc[Y==2, 1], s=50, c='yellow', label='Cluster 3')
#plt.scatter(X.iloc[Y==3, 0], X.iloc[Y==3, 1], s=50, c='green', label='Cluster 4')
#plt.scatter(X.iloc[Y==4, 0], X.iloc[Y==4, 1], s=50, c='orange', label='Cluster 5')
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=200, c='black', label='Centroids')
plt.title('Customer Groups')
plt.xlabel('opening price')
plt.ylabel('closing price')
plt.show()

#Analysis
from sklearn.metrics import accuracy_score, r2_score, confusion_matrix, precision_score, recall_score, f1_score
showitems={'linear regression':lr,'lasso regression':lasso,'logistic regression':logreg,'knn':knn,'gaussian naive bayes':gnb,'bernoulli naive bayes':bnb,'decision tree':dt,'random forest':rf,"svm":classifier}
regression_models = ['linear regression', 'lasso regression']
classification_models = ['logistic regression', 'knn', 'gaussian naive bayes',
                          'bernoulli naive bayes', 'decision tree', 'random forest', 'svm']

all_results = []

print("\nðŸ“Š Confusion Matrices & Classification Reports:\n")

for name, model in showitems.items():
    if name in regression_models:
        model.fit(X_train, y_train_reg)
        y_pred_reg = model.predict(X_test)
        all_results.append({
            "Model": name,
            "Type": "Regression",
            "Accuracy": np.nan,
            "RÂ² Score": r2_score(y_test_reg, y_pred_reg),
            "Precision": np.nan,
            "Recall": np.nan,
            "F1 Score": np.nan
        })

    elif name in classification_models:
        model.fit(X_train, y_train_clf)
        y_pred_clf = model.predict(X_test)
        y_pred_clf_encoded = le.transform(y_pred_clf)

        acc = accuracy_score(y_test_clf, y_pred_clf)
        r2 = r2_score(y_test_clf_encoded, y_pred_clf_encoded)
        prec = precision_score(y_test_clf, y_pred_clf, pos_label='up')
        rec = recall_score(y_test_clf, y_pred_clf, pos_label='up')
        f1 = f1_score(y_test_clf, y_pred_clf, pos_label='up')

        print(f"ðŸ”¹ Confusion Matrix for {name}:")
        print(confusion_matrix(y_test_clf, y_pred_clf))
        print()

        all_results.append({
            "Model": name,
            "Type": "Classification",
            "Accuracy": acc,
            "RÂ² Score": r2,
            "Precision": prec,
            "Recall": rec,
            "F1 Score": f1
        })

results_df = pd.DataFrame(all_results).sort_values(by=["Type", "Accuracy"], ascending=[True, False])
print("\nðŸ“ˆ Combined Model Performance Table:\n")
print(results_df)

"""Final Analysis                                                                 

The Random Forest classifier outperforms other models with the highest accuracy (82.1%) and strong precision (85%), making it the most reliable choice for this classification task. Decision Tree and Gaussian Naive Bayes follow but with lower accuracy and RÂ² scores, indicating weaker predictive power. Logistic Regression, Bernoulli Naive Bayes, and SVM show identical performance, suggesting limited model differentiation in this dataset. KNN performs the worst among classifiers. Regression models (Linear and Lasso) are not suitable here, given their low RÂ² scores and undefined classification metrics. Overall, Random Forest is the most effective and balanced model for this task.

"""